{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN - Movie Genre Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CST - 435 <br>\n",
    "Grand Canyon University<br>\n",
    "Created By: Caleb Klinger, Kyungchan Im<br>\n",
    "Professor: Isac Artzi\n",
    "\n",
    "We are going to perform a Convolutionary Neural Network to predict the genre based off from the poster image. <br> We will perform image classification by training the model by its categories. This dataset is from Kaggle, but originally from \n",
    "\n",
    "Wei-Ta Chu and Hung-Jui Guo, “Movie Genre Classification based on Poster Images with Deep Neural Networks,” Proceedings of International Workshop on Multimodal Understanding of Social, Affective and Subjective Attributes, pp. 39-45, 2017. (in conjunction with ACM Multimedia 2017)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Packages\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Deep Learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPool2D,Dense,Flatten,BatchNormalization,Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset on https://www.kaggle.com/datasets/raman77768/movie-classifier\n",
    "\n",
    "# Load the dataset\n",
    "movies = pd.read_csv('movie_dataset/train.csv') # Dataset containing genres with movie poster IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Biography</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>...</th>\n",
       "      <th>N/A</th>\n",
       "      <th>News</th>\n",
       "      <th>Reality-TV</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Short</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0086425</td>\n",
       "      <td>['Comedy', 'Drama']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0085549</td>\n",
       "      <td>['Drama', 'Romance', 'Music']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0086465</td>\n",
       "      <td>['Comedy']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0086567</td>\n",
       "      <td>['Sci-Fi', 'Thriller']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0086034</td>\n",
       "      <td>['Action', 'Adventure', 'Thriller']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id                                Genre  Action  Adventure   \n",
       "0  tt0086425                  ['Comedy', 'Drama']       0          0  \\\n",
       "1  tt0085549        ['Drama', 'Romance', 'Music']       0          0   \n",
       "2  tt0086465                           ['Comedy']       0          0   \n",
       "3  tt0086567               ['Sci-Fi', 'Thriller']       0          0   \n",
       "4  tt0086034  ['Action', 'Adventure', 'Thriller']       1          1   \n",
       "\n",
       "   Animation  Biography  Comedy  Crime  Documentary  Drama  ...  N/A  News   \n",
       "0          0          0       1      0            0      1  ...    0     0  \\\n",
       "1          0          0       0      0            0      1  ...    0     0   \n",
       "2          0          0       1      0            0      0  ...    0     0   \n",
       "3          0          0       0      0            0      0  ...    0     0   \n",
       "4          0          0       0      0            0      0  ...    0     0   \n",
       "\n",
       "   Reality-TV  Romance  Sci-Fi  Short  Sport  Thriller  War  Western  \n",
       "0           0        0       0      0      0         0    0        0  \n",
       "1           0        1       0      0      0         0    0        0  \n",
       "2           0        0       0      0      0         0    0        0  \n",
       "3           0        0       1      0      0         1    0        0  \n",
       "4           0        0       0      0      0         1    0        0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the basic information of the dataset\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7254 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7254/7254 [00:10<00:00, 677.45it/s]\n"
     ]
    }
   ],
   "source": [
    "X = [] # Image data\n",
    "# movies.shape[0] = number of iteration required to convert all pictures to numpy array\n",
    "\n",
    "# Normalizing the images to pixel values\n",
    "for i in tqdm(range(movies.shape[0])):\n",
    "    path = 'movie_dataset/Images/' + movies['Id'][i] + '.jpg'\n",
    "\n",
    "    # Load the image and resize it to 350x350 pixels\n",
    "    image = load_img(path, target_size=(350,350,3))\n",
    "\n",
    "    # Convert the image to array\n",
    "    image_array = img_to_array(image)\n",
    "\n",
    "    # Normalize the image\n",
    "    image_array = image_array/255\n",
    "\n",
    "    # Append the image to the list\n",
    "    X.append(np.array(image_array))\n",
    "\n",
    "# Convert the list to numpy array\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7254, 350, 350, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Genre', 'Action', 'Adventure', 'Animation', 'Biography',\n",
       "       'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy',\n",
       "       'History', 'Horror', 'Music', 'Musical', 'Mystery', 'N/A', 'News',\n",
       "       'Reality-TV', 'Romance', 'Sci-Fi', 'Short', 'Sport', 'Thriller', 'War',\n",
       "       'Western'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = movies.drop(['Id','Genre'],axis=1)\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=(5,5),activation='relu',input_shape=X_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters=32,kernel_size=(5,5),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=(5,5),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters=128,kernel_size=(5,5),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(25,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 346, 346, 16)      1216      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 346, 346, 16)      64        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 173, 173, 16)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 173, 173, 16)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 169, 169, 32)      12832     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 169, 169, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 84, 84, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 84, 84, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 80, 80, 64)        51264     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 80, 80, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 40, 40, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 40, 40, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 36, 36, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 36, 36, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 18, 18, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 18, 18, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 41472)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               5308544   \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 25)                1625      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5590393 (21.33 MB)\n",
      "Trainable params: 5589529 (21.32 MB)\n",
      "Non-trainable params: 864 (3.38 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "182/182 [==============================] - 383s 2s/step - loss: 0.6424 - accuracy: 0.1130 - val_loss: 0.3832 - val_accuracy: 0.0338\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 380s 2s/step - loss: 0.2999 - accuracy: 0.2718 - val_loss: 0.2460 - val_accuracy: 0.2226\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 387s 2s/step - loss: 0.2497 - accuracy: 0.3090 - val_loss: 0.2370 - val_accuracy: 0.3280\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 387s 2s/step - loss: 0.2415 - accuracy: 0.3193 - val_loss: 0.2405 - val_accuracy: 0.2874\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 382s 2s/step - loss: 0.2379 - accuracy: 0.3264 - val_loss: 0.2354 - val_accuracy: 0.2391\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 386s 2s/step - loss: 0.2353 - accuracy: 0.3384 - val_loss: 0.2340 - val_accuracy: 0.3666\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 392s 2s/step - loss: 0.2312 - accuracy: 0.3438 - val_loss: 0.2332 - val_accuracy: 0.2529\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 392s 2s/step - loss: 0.2278 - accuracy: 0.3490 - val_loss: 0.2348 - val_accuracy: 0.3646\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 395s 2s/step - loss: 0.2255 - accuracy: 0.3631 - val_loss: 0.2378 - val_accuracy: 0.2702\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 392s 2s/step - loss: 0.2213 - accuracy: 0.3660 - val_loss: 0.2350 - val_accuracy: 0.3170\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs=epochs,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('movie_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
